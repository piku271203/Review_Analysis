{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdf6e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "data=pd.read_csv('all_kindle_review.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e2004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3\n",
       "1  Great short read.  I didn't want to put it dow...       5\n",
       "2  I'll start by saying this is the first of four...       3\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4  I did not expect this type of book to be in li...       4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data[['reviewText','rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767e6d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefe092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e254138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARINDAM CHOUDHURY\\AppData\\Local\\Temp\\ipykernel_10268\\3208188810.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['rating']=df['rating'].apply(lambda x:0 if x<3 else 1)\n"
     ]
    }
   ],
   "source": [
    "## postive review is 1 and negative review is 0\n",
    "df['rating']=df['rating'].apply(lambda x:0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359c3d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24526a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARINDAM CHOUDHURY\\AppData\\Local\\Temp\\ipykernel_10268\\1654308119.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "## 1. Lower All the cases\n",
    "df['reviewText']=df['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d537fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may be short, but he's nothing to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read.  i didn't want to put it dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'll start by saying this is the first of four...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie is angela lansbury who carries pocketboo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i did not expect this type of book to be in li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may be short, but he's nothing to ...       1\n",
       "1  great short read.  i didn't want to put it dow...       1\n",
       "2  i'll start by saying this is the first of four...       1\n",
       "3  aggie is angela lansbury who carries pocketboo...       1\n",
       "4  i did not expect this type of book to be in li...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d017eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6bcc585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ARINDAM\n",
      "[nltk_data]     CHOUDHURY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "595c541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bs4) (4.14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb9588a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bba8ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20374dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load stopwords once\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Precompile regex\n",
    "regex_non_alpha = re.compile('[^a-zA-Z0-9- ]+')\n",
    "regex_url = re.compile(r'(http|https|ftp|ssh)://\\S+')\n",
    "\n",
    "# Remove special characters\n",
    "df.loc[:, 'reviewText'] = df['reviewText'].apply(lambda x: regex_non_alpha.sub(' ', str(x)))\n",
    "\n",
    "# Remove stopwords\n",
    "df.loc[:, 'reviewText'] = df['reviewText'].apply(lambda x: \" \".join([y for y in x.split() if y.lower() not in stop_words]))\n",
    "\n",
    "# Remove URLs\n",
    "df.loc[:, 'reviewText'] = df['reviewText'].apply(lambda x: regex_url.sub('', str(x)))\n",
    "\n",
    "# Remove HTML tags\n",
    "df.loc[:, 'reviewText'] = df['reviewText'].apply(lambda x: BeautifulSoup(str(x), 'lxml').get_text())\n",
    "\n",
    "# Remove extra spaces\n",
    "df.loc[:, 'reviewText'] = df['reviewText'].apply(lambda x: \" \".join(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0df4bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0a64e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92999f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bceb53e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\ARINDAM\n",
      "[nltk_data]     CHOUDHURY\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad79fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARINDAM CHOUDHURY\\AppData\\Local\\Temp\\ipykernel_10268\\1959687590.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reviewText']=df['reviewText'].apply(lambda x:lemmatize_words(x))\n"
     ]
    }
   ],
   "source": [
    "df['reviewText']=df['reviewText'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "683eb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['reviewText'],df['rating'],\n",
    "                                              test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94a05e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow=CountVectorizer()\n",
    "X_train_bow=bow.fit_transform(X_train).toarray()\n",
    "X_test_bow=bow.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef73e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train_tfidf=tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf=tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4048733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\arindam choudhury\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.15.3)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.4.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart_open>=1.8.1->gensim)\n",
      "  Downloading wrapt-2.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Downloading gensim-4.4.0-cp312-cp312-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.4 MB 5.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.8/24.4 MB 6.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.6/24.4 MB 6.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.1/24.4 MB 4.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.5/24.4 MB 4.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.8/24.4 MB 5.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.8/24.4 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.1/24.4 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.4/24.4 MB 4.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.4/24.4 MB 5.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.2/24.4 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.8/24.4 MB 4.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.4/24.4 MB 5.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.4/24.4 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.9/24.4 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.8/24.4 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 17.0/24.4 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.4/24.4 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.2/24.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.4 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.4.0-py3-none-any.whl (63 kB)\n",
      "Downloading wrapt-2.0.0-cp312-cp312-win_amd64.whl (60 kB)\n",
      "Installing collected packages: wrapt, smart_open, gensim\n",
      "\n",
      "   ---------------------------------------- 0/3 [wrapt]\n",
      "   ------------- -------------------------- 1/3 [smart_open]\n",
      "   ------------- -------------------------- 1/3 [smart_open]\n",
      "   ------------- -------------------------- 1/3 [smart_open]\n",
      "   ------------- -------------------------- 1/3 [smart_open]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   -------------------------- ------------- 2/3 [gensim]\n",
      "   ---------------------------------------- 3/3 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.4.0 smart_open-7.4.0 wrapt-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4c5730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your reviews are lemmatized\n",
    "X_train_tokens = [review.split() for review in X_train]  # train reviews\n",
    "X_test_tokens = [review.split() for review in X_test]    # test reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62cc4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train on your training data\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=X_train_tokens,  # tokenized sentences\n",
    "    vector_size=100,           # dimension of embeddings\n",
    "    window=5,                  # context window\n",
    "    min_count=1,               # ignore words with freq < 1\n",
    "    workers=4                  # parallel threads\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e9612bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_average_word2vec(tokens, model, vector_size):\n",
    "    vec = np.zeros(vector_size)  # initialize zero vector\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:     # check if word is in vocab\n",
    "            vec += model.wv[word]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        vec /= count              # average\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aec67547",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100  # same as in Word2Vec\n",
    "\n",
    "X_train_w2v = np.array([get_average_word2vec(tokens, w2v_model, vector_size) for tokens in X_train_tokens])\n",
    "X_test_w2v = np.array([get_average_word2vec(tokens, w2v_model, vector_size) for tokens in X_test_tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3caae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad7e56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model_bow=GaussianNB().fit(X_train_bow,y_train)\n",
    "nb_model_tfidf=GaussianNB().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a649d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "247853e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow=nb_model_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b45069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf=nb_model_bow.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f490c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[544, 265],\n",
       "       [746, 845]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f76b87ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW accuracy:  0.57875\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW accuracy: \",accuracy_score(y_test,y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3db852b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[533, 276],\n",
       "       [744, 847]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40f2e1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF accuracy:  0.575\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDF accuracy: \",accuracy_score(y_test,y_pred_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
